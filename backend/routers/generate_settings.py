from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import os
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LLM Configuration
GEMINI_MODEL = "gemini-2.5-pro"
GEMINI_TEMPERATURE = 0.8
GEMINI_MAX_OUTPUT_TOKENS = 10000 # 10k
GEMINI_TOP_P = 0.9
GEMINI_TOP_K = 40

router = APIRouter(prefix="/api", tags=["generate-settings"])

# Pydantic model for the request
class GenerateSettingsRequest(BaseModel):
    feel_choices: List[str]
    story_draws: List[str]
    inspirations: List[str] = []

# Pydantic model for the response
class GenerateSettingsResponse(BaseModel):
    success: bool
    message: str
    generated_content: dict

@router.post("/generateSettings", response_model=GenerateSettingsResponse)
async def generate_settings(request: GenerateSettingsRequest):
    """
    Generate story settings using LangChain and Gemini based on user choices.
    """
    logger.info(f"Received request: feel_choices={request.feel_choices}, story_draws={request.story_draws}, inspirations={request.inspirations}")
    
    try:
        # Check if GEMINI_API_KEY is set
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            logger.error("GEMINI_API_KEY environment variable is not set")
            raise HTTPException(
                status_code=500,
                detail="GEMINI_API_KEY environment variable is not set. Please set it in your environment."
            )
        
        logger.info(f"GEMINI_API_KEY is set (length: {len(gemini_api_key)})")
        
        # Initialize the Gemini LLM
        # Using gemini-2.5-pro as it's the latest and most capable text model
        logger.info(f"Initializing Gemini LLM with model: {GEMINI_MODEL}")
        llm = ChatGoogleGenerativeAI(
            model=GEMINI_MODEL,
            temperature=GEMINI_TEMPERATURE,
            max_output_tokens=GEMINI_MAX_OUTPUT_TOKENS,
            top_p=GEMINI_TOP_P,
            top_k=GEMINI_TOP_K,
            google_api_key=gemini_api_key
        )
        logger.info("Gemini LLM initialized successfully")
        
        # Create a prompt template for story generation
        logger.info("Creating prompt template...")
        prompt_template = PromptTemplate(
            input_variables=["feel_choices", "story_draws", "inspirations"],
            template="""
            Create a story concept based on:
            Feel: {feel_choices}
            Focus: {story_draws}
            Inspiration: {inspirations}
            
            Generate a concise story with:
            - Title: [creative title]
            - Character: [main character description]
            - Setting: [unique world/setting]
            - Hook: [plot hook/inciting incident]
            
            Keep it engaging and suitable for a comic/story.
            """
        )
        logger.info("Prompt template created successfully")
        
        # Create the LLM chain using modern RunnableSequence
        logger.info("Creating LLM chain...")
        chain = prompt_template | llm
        logger.info("LLM chain created successfully")
        
        # Generate the story settings
        logger.info("Running LLM chain...")
        chain_input = {
            "feel_choices": ", ".join(request.feel_choices),
            "story_draws": ", ".join(request.story_draws),
            "inspirations": ", ".join(request.inspirations) if request.inspirations else "none specified"
        }
        logger.info(f"Chain input: {chain_input}")
        
        result = chain.invoke(chain_input)
        logger.info(f"LLM chain completed successfully. Result length: {len(str(result))}")
        logger.info(f"Result content: {result.content if hasattr(result, 'content') else result}")
        
        # Parse the LLM response and structure it
        # For now, we'll return the raw response, but you could add parsing logic here
        generated_content = {
            "story_title": "Generated by Gemini",
            "main_character": "Generated by Gemini", 
            "setting": "Generated by Gemini",
            "plot_hook": "Generated by Gemini",
            "inspirations_used": request.inspirations,
            "llm_response": result,
            "input_feelings": request.feel_choices,
            "input_draws": request.story_draws
        }
        
        logger.info("Successfully created response object")
        
        return GenerateSettingsResponse(
            success=True,
            message="Settings generated successfully using Gemini",
            generated_content=generated_content
        )
        
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        logger.error(f"Unexpected error in generate_settings: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error generating settings: {str(e)}"
        ) 